"""
Ana Chatbot Sistemi
==================

Bu dosya tÃ¼m sistemleri koordine eden ana yÃ¶nlendirme sistemidir.
- LLM ile akÄ±ÅŸ yÃ¶nlendirmesi
- RAG, Animal, Emotion sistemlerini Ã§aÄŸÄ±rma
- Web arayÃ¼zÃ¼ yÃ¶netimi
"""

import os
import re
import html
from typing import Any, Dict
from fastapi import FastAPI, HTTPException
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI

# Sistem modÃ¼llerini import et
from emotion_system import EmotionChatbot
from animal_system import route_animals, _animal_emoji
from rag_service import rag_service

load_dotenv()

app = FastAPI(title="AkÄ±llÄ± Chatbot Sistemi", version="2.0.0")
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Global chatbot instance
chatbot_instance: EmotionChatbot | None = None

# RAG modelini asenkron olarak Ã¶nceden yÃ¼kle
print("[STARTUP] RAG modeli asenkron olarak yÃ¼kleniyor...")
rag_service.preload_model_async()

# GÃ¼venlik sabitleri
MAX_MESSAGE_LENGTH = 2000  # Maksimum mesaj uzunluÄŸu
MAX_TOKENS_PER_REQUEST = 1000  # Maksimum token sayÄ±sÄ±
DANGEROUS_PATTERNS = [
    r'<script[^>]*>.*?</script>',  # Script injection
    r'javascript:',  # JavaScript URL
    r'data:text/html',  # Data URL
    r'vbscript:',  # VBScript
    r'on\w+\s*=',  # Event handlers
    r'<iframe[^>]*>',  # Iframe injection
    r'<object[^>]*>',  # Object injection
    r'<embed[^>]*>',  # Embed injection
    r'<link[^>]*>',  # Link injection
    r'<meta[^>]*>',  # Meta injection
]

# RAG kaynaklarÄ±
RAG_SOURCES = {
    "Learning_Python.pdf": {"id": "pdf-python", "emoji": "ðŸ", "alias": "python"},
    "gerekceli_anayasa.pdf": {"id": "pdf-anayasa", "emoji": "âš–ï¸", "alias": "anayasa"},
    "clean_architecture.pdf": {"id": "pdf-clean", "emoji": "ðŸ—ï¸", "alias": "clean"},
}

# Static files (CSS/JS)
STATIC_DIR = Path(__file__).parent / "static"
try:
    STATIC_DIR.mkdir(parents=True, exist_ok=True)
except Exception:
    pass
app.mount("/static", StaticFiles(directory=str(STATIC_DIR)), name="static")


def _sanitize_input(text: str) -> str:
    """GÃ¼venli input sanitization - injection saldÄ±rÄ±larÄ±nÄ± Ã¶nler"""
    if not text:
        return ""
    
    # HTML escape
    text = html.escape(text, quote=True)
    
    # Tehlikeli pattern'leri kontrol et
    for pattern in DANGEROUS_PATTERNS:
        if re.search(pattern, text, re.IGNORECASE):
            print(f"[SECURITY] Tehlikeli pattern tespit edildi: {pattern}")
            return "[GÃ¼venlik nedeniyle mesaj filtrelendi]"
    
    # Fazla boÅŸluklarÄ± temizle
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text


def _validate_message_length(text: str) -> bool:
    """Mesaj uzunluÄŸunu kontrol eder"""
    return len(text) <= MAX_MESSAGE_LENGTH


def _estimate_tokens(text: str) -> int:
    """YaklaÅŸÄ±k token sayÄ±sÄ±nÄ± hesaplar (TÃ¼rkÃ§e iÃ§in)"""
    # TÃ¼rkÃ§e iÃ§in yaklaÅŸÄ±k hesaplama: 1 token â‰ˆ 4 karakter
    return len(text) // 4


def _get_flow_decision(user_message: str) -> str:
    """LLM ile akÄ±ÅŸ yÃ¶nlendirmesi yapar (ANIMAL/RAG/EMOTION)"""
    try:
        # Token kontrolÃ¼
        estimated_tokens = _estimate_tokens(user_message)
        if estimated_tokens > MAX_TOKENS_PER_REQUEST:
            print(f"[SECURITY] Ã‡ok fazla token: {estimated_tokens}")
            return "EMOTION"  # GÃ¼venli fallback
        
        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": """KullanÄ±cÄ±nÄ±n mesajÄ±nÄ± analiz et ve ÅŸu akÄ±ÅŸlardan birini seÃ§:

Ã–NEMLÄ° KURALLAR:
1. EÄŸer kullanÄ±cÄ± BÄ°LGÄ° istiyorsa (nedir, nasÄ±l, aÃ§Ä±kla, tanÄ±m, principle, concept, theory) â†’ RAG
2. EÄŸer kullanÄ±cÄ± HAYVAN istiyorsa (kÃ¶pek, kedi, tilki, Ã¶rdek fotoÄŸraf/bilgi) â†’ ANIMAL  
3. EÄŸer kullanÄ±cÄ± SOHBET/DUYGU istiyorsa (merhaba, nasÄ±lsÄ±n, Ã¼zgÃ¼nÃ¼m, mutluyum) â†’ EMOTION

AkÄ±ÅŸlar:
- ANIMAL: KÃ¶pek, kedi, tilki, Ã¶rdek fotoÄŸraf/bilgi isteÄŸi
- RAG: Python, Anayasa, Clean Architecture, teknik terimler, bilgi sorularÄ±, "nedir", "nasÄ±l", "aÃ§Ä±kla", "tanÄ±m", "principle", "concept"
- EMOTION: Duygu analizi, sohbet, normal konuÅŸma

Sadece ÅŸu yanÄ±tlardan birini ver: ANIMAL, RAG, EMOTION"""},
                {"role": "user", "content": user_message}
            ],
            temperature=0.1,
            max_tokens=15
        )
        flow_decision = completion.choices[0].message.content or ""
        return flow_decision.strip()
    except Exception as e:
        print(f"[FLOW] LLM yÃ¶nlendirme hatasÄ±: {e}")
        return "EMOTION"  # VarsayÄ±lan


def _process_rag_flow(user_message: str) -> Dict[str, Any] | None:
    """RAG akÄ±ÅŸÄ±nÄ± iÅŸler - PDF'lerden bilgi Ã§eker"""
    t = user_message.lower()
    # Heuristic: explicit source keywords
    if "anayasa" in t:
        source = "gerekceli_anayasa.pdf"
    elif ("clean architecture" in t or "clean architecture".replace(" ", "_") in t or 
          ("clean" in t and "architecture" in t) or "acyclic" in t or "dependency" in t or 
          "principle" in t or "principles" in t or "dependencies" in t):
        source = "clean_architecture.pdf"
    elif "python" in t:
        source = "Learning_Python.pdf"
    else:
        # If generic question, try general retrieval (no source filter)
        keywords = ["pdf", "belge", "dokÃ¼man", "Ã¶zetle", "aÃ§Ä±kla", "nedir", "nasÄ±l", "anlat", "tanÄ±m"]
        if not any(k in t for k in keywords):
            return None
        chunks = rag_service.retrieve_top(user_message, top_k=4)
        if not chunks:
            return None
        context = "\n\n".join([c.get("text", "") for c in chunks])
        sources = list({(c.get("metadata", {}) or {}).get("source", "?") for c in chunks})
        prompt = f"BAÄžLAM:\n{context}\n\nSORU: {user_message}\nYANIT:"

        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Sen bir bilgi asistanÄ±sÄ±n. KullanÄ±cÄ±nÄ±n sorularÄ±nÄ± verilen baÄŸlam bilgilerini kullanarak yanÄ±tla. TÃ¼rkÃ§e, kÄ±sa ve net yanÄ±tlar ver. BaÄŸlam bilgisini kullan ama gereksiz detay verme. EÄŸer baÄŸlamda yeterli bilgi yoksa bunu belirt. YanÄ±tÄ±nÄ± doÄŸrudan metin olarak ver (JSON formatÄ±nda deÄŸil). Maksimum 5 cÃ¼mle ile yanÄ±tla. Ã–zellikle Clean Architecture, Python, Anayasa konularÄ±nda uzmanlaÅŸmÄ±ÅŸsÄ±n."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.2,
        )
        answer = completion.choices[0].message.content or ""
        # Pick first known source for UI hint
        lit = None
        for s in sources:
            if s in RAG_SOURCES:
                lit = s
                break
        ui = RAG_SOURCES.get(lit or "", None)
        return {
            "rag": True,
            "response": answer,
            "rag_source": ui.get("id") if ui else None,
            "rag_emoji": ui.get("emoji") if ui else None,
        }

    # Source-filtered retrieval
    chunks = rag_service.retrieve_by_source(user_message, source_filename=source, top_k=4)
    if not chunks:
        return None
    context = "\n\n".join([c.get("text", "") for c in chunks])
    prompt = f"BAÄžLAM:\n{context}\n\nSORU: {user_message}\nYANIT:"
    
    completion = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "Sen bir bilgi asistanÄ±sÄ±n. KullanÄ±cÄ±nÄ±n sorularÄ±nÄ± verilen baÄŸlam bilgilerini kullanarak yanÄ±tla. TÃ¼rkÃ§e, kÄ±sa ve net yanÄ±tlar ver. BaÄŸlam bilgisini kullan ama gereksiz detay verme. EÄŸer baÄŸlamda yeterli bilgi yoksa bunu belirt. YanÄ±tÄ±nÄ± doÄŸrudan metin olarak ver (JSON formatÄ±nda deÄŸil). Maksimum 5 cÃ¼mle ile yanÄ±tla. Ã–zellikle Clean Architecture, Python, Anayasa konularÄ±nda uzmanlaÅŸmÄ±ÅŸsÄ±n."},
            {"role": "user", "content": prompt},
        ],
        temperature=0.2,
    )
    answer = completion.choices[0].message.content or ""
    ui = RAG_SOURCES.get(source)
    return {
        "rag": True,
        "response": answer,
        "rag_source": ui.get("id"),
        "rag_emoji": ui.get("emoji"),
    }


def _process_animal_flow(user_message: str) -> Dict[str, Any] | None:
    """Hayvan akÄ±ÅŸÄ±nÄ± iÅŸler - fotoÄŸraf/bilgi getirir"""
    animal_result = route_animals(user_message, client)
    if animal_result:
        animal = str(animal_result.get("animal", ""))
        out: Dict[str, Any] = {
            "animal": animal,
            "type": animal_result.get("type"),
            "animal_emoji": _animal_emoji(animal),
        }
        if animal_result.get("type") == "image":
            out["image_url"] = animal_result.get("image_url")
            out["response"] = f"{_animal_emoji(animal)} {animal.capitalize()} fotoÄŸrafÄ± hazÄ±r."
        else:
            out["response"] = animal_result.get("text", "")
        return out
    return None


def _process_emotion_flow(user_message: str) -> Dict[str, Any]:
    """Duygu akÄ±ÅŸÄ±nÄ± iÅŸler - duygu analizi ve sohbet"""
    global chatbot_instance
    if chatbot_instance is None:
        chatbot_instance = EmotionChatbot(client)
    
    result = chatbot_instance.chat(user_message)
    stats = {
        "requests": chatbot_instance.stats["requests"],
        "last_request_at": chatbot_instance.stats["last_request_at"],
    }
    # result: { response: str, first_emoji?: str, second_emoji?: str, request_debug?: str }
    out = {"response": result.get("response", ""), "stats": stats}
    if "first_emoji" in result:
        out["first_emoji"] = result["first_emoji"]
    if "second_emoji" in result:
        out["second_emoji"] = result["second_emoji"]
    if "request_debug" in result:
        out["request_debug"] = result["request_debug"]
    return out


@app.get("/", response_class=HTMLResponse)
def index() -> HTMLResponse:
    """Ana sayfa HTML'ini dÃ¶ndÃ¼rÃ¼r"""
    template_path = Path(__file__).parent / "templates" / "index.html"
    try:
        html = template_path.read_text(encoding="utf-8")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"HTML yÃ¼klenemedi: {e}")
    return HTMLResponse(content=html)


@app.post("/chat")
def chat(payload: Dict[str, Any]) -> Dict[str, Any]:
    """Ana chat endpoint'i - akÄ±ÅŸ yÃ¶nlendirmesi yapar"""
    user_message = str(payload.get("message", "")).strip()
    
    # GÃ¼venlik kontrolleri
    if not user_message:
        return {"error": "Mesaj boÅŸ olamaz"}
    
    # Mesaj uzunluk kontrolÃ¼
    if not _validate_message_length(user_message):
        return {"error": f"Mesaj Ã§ok uzun. Maksimum {MAX_MESSAGE_LENGTH} karakter olabilir."}
    
    # Input sanitization
    user_message = _sanitize_input(user_message)
    if user_message == "[GÃ¼venlik nedeniyle mesaj filtrelendi]":
        return {"error": "GÃ¼venlik nedeniyle mesaj filtrelendi"}
    
    # Token kontrolÃ¼
    estimated_tokens = _estimate_tokens(user_message)
    if estimated_tokens > MAX_TOKENS_PER_REQUEST:
        return {"error": f"Ã‡ok fazla token. Maksimum {MAX_TOKENS_PER_REQUEST} token olabilir."}

    try:
        # AÅžAMA 1: LLM ile akÄ±ÅŸ yÃ¶nlendirmesi
        print("[FLOW] AÅžAMA 1: LLM akÄ±ÅŸ yÃ¶nlendirmesi baÅŸlÄ±yor...")
        flow_decision = _get_flow_decision(user_message)
        print(f"[FLOW] LLM akÄ±ÅŸ kararÄ±: {flow_decision}")

        # AÅžAMA 2: SeÃ§ilen akÄ±ÅŸa gÃ¶re iÅŸleme
        if flow_decision == "RAG":
            print("[FLOW] AÅžAMA 2: RAG akÄ±ÅŸÄ± Ã§alÄ±ÅŸÄ±yor...")
            result = _process_rag_flow(user_message)
            if result:
                return result
        elif flow_decision == "ANIMAL":
            print("[FLOW] AÅžAMA 2: Hayvan akÄ±ÅŸÄ± Ã§alÄ±ÅŸÄ±yor...")
            result = _process_animal_flow(user_message)
            if result:
                return result
        elif flow_decision == "EMOTION":
            print("[FLOW] AÅžAMA 2: Duygu akÄ±ÅŸÄ± Ã§alÄ±ÅŸÄ±yor...")
            result = _process_emotion_flow(user_message)
            if result:
                return result
        
        # Fallback: VarsayÄ±lan duygu akÄ±ÅŸÄ±
        print("[FLOW] Fallback: Duygu akÄ±ÅŸÄ± Ã§alÄ±ÅŸÄ±yor...")
        result = _process_emotion_flow(user_message)
        return result

    except HTTPException as e:
        return {"error": e.detail}
    except Exception as e:
        return {"error": str(e)}


# Ã‡alÄ±ÅŸtÄ±rma:
# uvicorn api_web_chatbot:app --host 0.0.0.0 --port 8000 --reload
